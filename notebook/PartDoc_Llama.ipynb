{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fa6ff1-94f3-40c3-a961-037c4e7084eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, json, os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Iterable, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851cb2e8-5295-43ae-b9aa-f2332cf7a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Paths (EDIT THESE)\n",
    "# ----------------------------\n",
    "DOC_PATH = Path(\"../doc/RDPro.md\")\n",
    "PY_PATH  = Path(\"../python/ndvi.py\")\n",
    "assert DOC_PATH.exists(), f\"Missing: {DOC_PATH}\"\n",
    "assert PY_PATH.exists(), f\"Missing: {PY_PATH}\"\n",
    "\n",
    "rdpro_text = DOC_PATH.read_text(encoding=\"utf-8\")\n",
    "py_code = PY_PATH.read_text(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3a1513-bb10-404c-bc34-48a62d38b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    chunk_id: str\n",
    "    heading_path: str\n",
    "    level: int\n",
    "    text: str\n",
    "\n",
    "def chunk_markdown_by_headings(md: str) -> List[Chunk]:\n",
    "    lines = md.splitlines()\n",
    "    starts = []\n",
    "    for i, line in enumerate(lines):\n",
    "        m = re.match(r\"^(#{2,3})\\s+(.*\\S)\\s*$\", line)\n",
    "        if m:\n",
    "            starts.append((i, len(m.group(1)), m.group(2).strip()))\n",
    "\n",
    "    if not starts:\n",
    "        return [Chunk(\"c0000\", \"DOC\", 1, md.strip() + \"\\n\")]\n",
    "\n",
    "    chunks: List[Chunk] = []\n",
    "    current_h2: Optional[str] = None\n",
    "\n",
    "    for idx, (start_i, level, title) in enumerate(starts):\n",
    "        end_i = starts[idx + 1][0] if idx + 1 < len(starts) else len(lines)\n",
    "        body = \"\\n\".join(lines[start_i:end_i]).strip() + \"\\n\"\n",
    "\n",
    "        if level == 2:\n",
    "            current_h2 = title\n",
    "            heading_path = current_h2\n",
    "        else:\n",
    "            heading_path = f\"{current_h2} / {title}\" if current_h2 else title\n",
    "\n",
    "        chunks.append(Chunk(f\"c{idx:04d}\", heading_path, level, body))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def select_chunks_manual(chunks: List[Chunk], include_keywords: List[str]) -> List[Chunk]:\n",
    "    inc = [k.lower() for k in include_keywords]\n",
    "    selected: List[Chunk] = []\n",
    "    for ch in chunks:\n",
    "        hay = (ch.heading_path + \"\\n\" + ch.text).lower()\n",
    "        if any(k in hay for k in inc):\n",
    "            selected.append(ch)\n",
    "\n",
    "    # de-dupe (preserve order)\n",
    "    seen = set()\n",
    "    uniq: List[Chunk] = []\n",
    "    for ch in selected:\n",
    "        if ch.chunk_id not in seen:\n",
    "            uniq.append(ch)\n",
    "            seen.add(ch.chunk_id)\n",
    "    return uniq\n",
    "\n",
    "def select_chunks_manual_api_keys(chunks: List[Chunk], api_keys: List[str]) -> List[Chunk]:\n",
    "    \"\"\"\n",
    "    Strict manual selection: only select chunks that contain at least one explicit API key.\n",
    "    This prevents pulling unrelated chunks like Flatten/Explode/Reshape unless you include them.\n",
    "    \"\"\"\n",
    "    keys = [k.lower() for k in api_keys]\n",
    "\n",
    "    selected: List[Chunk] = []\n",
    "    for ch in chunks:\n",
    "        hay = (ch.heading_path + \"\\n\" + ch.text).lower()\n",
    "        if any(key in hay for key in keys):\n",
    "            selected.append(ch)\n",
    "\n",
    "    # de-dupe (preserve order)\n",
    "    seen = set()\n",
    "    uniq: List[Chunk] = []\n",
    "    for ch in selected:\n",
    "        if ch.chunk_id not in seen:\n",
    "            uniq.append(ch)\n",
    "            seen.add(ch.chunk_id)\n",
    "    return uniq\n",
    "\n",
    "def make_doc_pack(selected: List[Chunk]) -> str:\n",
    "    out = []\n",
    "    for ch in selected:\n",
    "        out.append(f\"### DOC CHUNK {ch.chunk_id}: {ch.heading_path}\\n{ch.text}\\n\")\n",
    "    return \"\\n\".join(out).strip() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6468edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = os.environ.get(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "MODEL = os.environ.get(\"OLLAMA_MODEL\", \"llama3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee3d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a geospatial data engineer and Spark systems expert.\n",
    "\n",
    "Task: Convert a given geospatial Python script into Scala code that runs on RDPro (Spark-based raster processing) on Apache Spark.\n",
    "\n",
    "You must understand Spark execution and produce distributed, RDD-based Scala.\n",
    "\n",
    "Environment & paths:\n",
    "- Determine whether output paths should be treated as local or distributed based on Spark configuration and the URI scheme.\n",
    "- You MAY use standard Spark/Scala APIs for this (SparkConf, SparkContext.hadoopConfiguration, java.net.URI, java.nio.file).\n",
    "- You MUST NOT invent any RDPro path utilities.\n",
    "\n",
    "Hard rules:\n",
    "1) Output MUST be valid Scala that compiles as a Spark job (a complete file). Include:\n",
    "   - necessary imports\n",
    "   - a runnable entrypoint: `object JobName { def main(args:Array[String]):Unit = ... }` (or `extends App`)\n",
    "   - SparkSession initialization\n",
    "   - spark.stop() at the end (in finally or equivalent)\n",
    "2) Use ONLY RDPro APIs that appear in the provided DOC CHUNKS.\n",
    "   - If a method signature is not shown in DOC CHUNKS, do NOT guess.\n",
    "3) Do NOT invent RDPro APIs, overloads, implicits, or helper utilities. No hidden \"magic\" conversions.\n",
    "4) Preserve semantics of the Python: raster IO, pixel math, focal ops, masking/nodata, reprojection/resample if present.\n",
    "5) Distributed correctness:\n",
    "   - Avoid driver-side operations: do NOT call collect/toLocalIterator unless required by the Python semantics.\n",
    "   - Prefer RDPro RasterRDD end-to-end when available in DOC CHUNKS.\n",
    "6) Raster alignment robustness:\n",
    "   - If not in DOC CHUNKS, fail fast: throw a clear runtime error explaining alignment is required but unsupported with available APIs.\n",
    "7) Performance guidance (Spark-level only):\n",
    "   - You MAY set Spark SQL / Spark configs and use standard Spark operations (repartition/coalesce/cache/persist) ONLY when:\n",
    "     (a) it does not change semantics, and\n",
    "     (b) it is justified by an obvious pipeline boundary (e.g., before a wide op / expensive reuse).\n",
    "8) Lambdas:\n",
    "   - When passing lambdas to RDPro functions (e.g., mapPixels), add explicit parameter and return types so Scala compiles.\n",
    "9) CLI args:\n",
    "   - If the Python has input/output paths, read them from args with safe defaults and validation.\n",
    "   - Do not introduce extra parameters not implied by the Python.\n",
    "\n",
    "Output format (strict):\n",
    "- First: Scala file content only (NO markdown fences).\n",
    "- After the Scala: a \"NOTES\" section listing:\n",
    "  (a) RDPro APIs used (names only)\n",
    "  (b) Unsupported operations and why (especially if missing alignment/warp APIs)\n",
    "  (c) Assumptions about IO paths / bands / nodata / CRS / environment detection logic\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49fd3f1-8ae0-4584-8024-9560fa1ad238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Manual \"keys\" (what you used before)\n",
    "# These are NOT necessarily filenames; aliases map them to doc files.\n",
    "# ----------------------------\n",
    "# ---- MANUAL KEYWORDS (edit this list) ----\n",
    "NDVI_KEYS = [\n",
    "    \"setup\",\n",
    "    \"geoTiff\",\n",
    "    \"rastermetadata\",\n",
    "    \"overlay\",          # stack red + nir\n",
    "    \"mapPixels\",        # compute NDVI\n",
    "    \"saveAsGeoTiff\",    # write output\n",
    "    \"GeoTiffWriter\",    # compression + write options\n",
    "    \"Compression\",      # (optional) forces pulling compression option lines\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f204695-ae8b-4a14-8c9b-c06e8fdcdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(doc_pack: str, py_code: str) -> str:\n",
    "    return f\"\"\"\n",
    "RDPro documentation (relevant DOC CHUNKS only):\n",
    "{doc_pack}\n",
    "\n",
    "Python script:\n",
    "{py_code}\n",
    "\n",
    "Task:\n",
    "Translate the Python script into Scala targeting RDPro on Spark.\n",
    "Use ONLY APIs described in the DOC CHUNKS.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa381419-7d3e-4e7d-8526-5d6ff2b48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_markdown_by_headings(rdpro_text)\n",
    "manual_selected = select_chunks_manual_api_keys(chunks, NDVI_KEYS)\n",
    "doc_pack = make_doc_pack(manual_selected)\n",
    "user_prompt = build_user_prompt(doc_pack, py_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d8e0ab-cef2-49e2-a8f7-acb66c9ed132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual chunks: 14\n",
      "Prompt chars: 19393\n",
      "Saved: runs/manual_oracle/prompt_manual.txt\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Save prompt + doc selection (optional)\n",
    "# ----------------------------\n",
    "OUT_DIR = Path(\"./runs/workspace\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(OUT_DIR / \"prompt_manual.txt\").write_text(user_prompt, encoding=\"utf-8\")\n",
    "(OUT_DIR / \"doc_selection.json\").write_text(\n",
    "    json.dumps([{\"id\": c.chunk_id, \"heading\": c.heading_path} for c in manual_selected], indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Manual chunks:\", len(manual_selected))\n",
    "print(\"Prompt chars:\", len(user_prompt))\n",
    "print(\"Saved:\", OUT_DIR / \"prompt_manual.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5bb63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ollama OK @ http://localhost:11434\n",
      "Available models: ['llama3:latest', 'tinyllama:latest'] \n",
      "Selected MODEL: llama3\n",
      "WARNING: Selected MODEL not in /api/tags list. If calls fail, set OLLAMA_MODEL to one of the listed names.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Ollama sanity check\n",
    "# ----------------------------\n",
    "def ollama_healthcheck() -> None:\n",
    "    import requests\n",
    "    try:\n",
    "        r = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=10)\n",
    "        r.raise_for_status()\n",
    "        models = [m.get(\"name\") for m in r.json().get(\"models\", [])]\n",
    "        print(\"\\nOllama OK @\", OLLAMA_URL)\n",
    "        print(\"Available models:\", models[:10], \"...\" if len(models) > 10 else \"\")\n",
    "        print(\"Selected MODEL:\", MODEL)\n",
    "        if models and MODEL not in models:\n",
    "            print(\"WARNING: Selected MODEL not in /api/tags list. If calls fail, set OLLAMA_MODEL to one of the listed names.\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nOllama NOT reachable at\", OLLAMA_URL)\n",
    "        print(\"Error:\", repr(e))\n",
    "        raise\n",
    "\n",
    "ollama_healthcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3d69f0-fded-4d09-85bd-642f9369fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote: runs/manual_oracle/Job.manual.llama.scala\n",
      "LLM latency: 56.77 s\n",
      "\n",
      "--- Preview ---\n",
      " Here is the translated Scala code targeting RDPro on Spark:\n",
      "\n",
      "```scala\n",
      "import edu.ucr.cs.bdlab.raptor.SparkRaptor\n",
      "import org.apache.spark.SparkContext\n",
      "import org.apache.spark.rdd.RDD\n",
      "\n",
      "object NDVI {\n",
      "  def main(args: Array[String]): Unit = {\n",
      "    val sc = SparkRaptor.getContext()\n",
      "    val redPath = \"/Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLMagent/data/landsat8/LA/B4/LC08_L2SP_040037_20250827_20250903_02_T1_SR_B4.TIF\"\n",
      "    val nirPath = \"/Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLMagent/data/landsat8/LA/B5/LC08_L2SP_040037_20250827_20250903_02_T1_SR_B5.TIF\"\n",
      "    val outNdviPath = \"/Users/clockorangezoe/Documents/phd_projects/code/geoAI/RDProLLMagent/python/ndvi.py\"\n",
      "\n",
      "    // Read Red and NIR rasters\n",
      "    val redRaster = sc.hdfFile(redPath, \"B4\")\n",
      "    val nirRaster = sc.hdfFile(nirPath, \"B5\")\n",
      "\n",
      "    // Calculate NDVI\n",
      "    val ndviPixels = redRaster.mapPixels((re\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Run LLaMA locally via Ollama\n",
    "# ----------------------------\n",
    "def run_llm(prompt: str) -> Tuple[str, float]:\n",
    "    import requests\n",
    "    t0 = time.time()\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        # Optional tuning knobs (uncomment if desired):\n",
    "        # \"options\": {\"temperature\": 0.2, \"num_ctx\": 8192},\n",
    "    }\n",
    "    r = requests.post(f\"{OLLAMA_URL}/api/chat\", json=payload, timeout=600)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    text = data[\"message\"][\"content\"].strip()\n",
    "    return text, time.time() - t0\n",
    "\n",
    "scala_out, dt = run_llm(user_prompt)\n",
    "(OUT_DIR / \"Job.manual.llama.scala\").write_text(scala_out, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nWrote:\", OUT_DIR / \"Job.manual.llama.scala\")\n",
    "print(\"LLM latency:\", round(dt, 2), \"s\")\n",
    "print(\"\\n--- Preview ---\\n\", scala_out[:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc60da-ca53-4071-bd13-b3b82e53fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
